{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330.54397588936\n",
      "(240, 240)\n",
      "[[2.3928182 2.3927739 2.3927293 ... 2.3984377 2.3983934 2.398349 ]\n",
      " [2.3929806 2.3929362 2.3928916 ... 2.398575  2.3985305 2.398486 ]\n",
      " [2.3937876 2.3930986 2.393054  ... 2.3987124 2.3986678 2.3986232]\n",
      " ...\n",
      " [2.41195   2.4118824 2.4118145 ... 2.4201822 2.4201145 2.4200466]\n",
      " [2.4121325 2.4120646 2.4119966 ... 2.420343  2.420275  2.420207 ]\n",
      " [2.4104166 2.412247  2.4121788 ... 2.4205039 2.420436  2.4203677]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot produce output of size 3563100x3563100 (size too large)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c952983ad610>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;31m#val_turb22 = linearint2(np.vstack((lala, lolo)).T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m \u001b[0mval_turb22\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearint2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlala\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlolo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0mval_turb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_turb0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0mval_turb2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlats0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mval_turb22\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/development/python/miniconda3/lib/python3.7/site-packages/scipy/interpolate/interpolate.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, y, dx, dy, assume_sorted)\u001b[0m\n\u001b[1;32m    299\u001b[0m                                 (self.y_min, self.y_max)))\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbisplev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/development/python/miniconda3/lib/python3.7/site-packages/scipy/interpolate/_fitpack_impl.py\u001b[0m in \u001b[0;36mbisplev\u001b[0;34m(x, y, tck, dx, dy)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"First two entries should be rank-1 arrays.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m     \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fitpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bispev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mky\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mier\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid input data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot produce output of size 3563100x3563100 (size too large)"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "#################################################################\n",
    "###  This program is part of PyRite  v1.0                     ### \n",
    "###  Copy Right (c): 2019, Yunmeng Cao                        ###  \n",
    "###  Author: Yunmeng Cao                                      ###                                                          \n",
    "###  Email : ymcmrs@gmail.com                                 ###\n",
    "###  Univ. : King Abdullah University of Science & Technology ###   \n",
    "#################################################################\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import argparse\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "import scipy.interpolate as intp\n",
    "from scipy.optimize import leastsq\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "from pyrite import elevation_models\n",
    "from pyrite import _utils as ut\n",
    "from pykrige import OrdinaryKriging\n",
    "\n",
    "import matlab.engine # using matlab to estimate the variogram parameters\n",
    "from mintpy.utils import ptime\n",
    "###############################################################\n",
    "\n",
    "model_dict = {'linear': elevation_models.linear_elevation_model,\n",
    "                      'onn': elevation_models.onn_elevation_model,\n",
    "                      'onn_linear': elevation_models.onn_linear_elevation_model,\n",
    "                      'exp': elevation_models.exp_elevation_model,\n",
    "                      'exp_linear': elevation_models.exp_linear_elevation_model}\n",
    "\n",
    "residual_dict = {'linear': elevation_models.residuals_linear,\n",
    "                      'onn': elevation_models.residuals_onn,\n",
    "                      'onn_linear': elevation_models.residuals_onn_linear,\n",
    "                      'exp': elevation_models.residuals_exp,\n",
    "                      'exp_linear': elevation_models.residuals_exp_linear}\n",
    "\n",
    "initial_dict = {'linear': elevation_models.initial_linear,\n",
    "                      'onn': elevation_models.initial_onn,\n",
    "                      'onn_linear': elevation_models.initial_onn_linear,\n",
    "                      'exp': elevation_models.initial_exp,\n",
    "                      'exp_linear': elevation_models.initial_exp_linear}\n",
    "\n",
    "para_numb_dict = {'linear': 2,\n",
    "                  'onn' : 3,\n",
    "                  'onn_linear':4,\n",
    "                  'exp':2,\n",
    "                  'exp_linear':3}\n",
    "\n",
    "def remove_ramp(lat,lon,data):\n",
    "    # mod = a*x + b*y + c*x*y\n",
    "    lat = lat/180*np.pi\n",
    "    lon = lon/180*np.pi  \n",
    "    lon = lon*np.cos(lat) # to get isometrics coordinates\n",
    "    \n",
    "    p0 = [0.0001,0.0001,0.0001,0.0000001]\n",
    "    plsq = leastsq(residual_trend,p0,args = (lat,lon,data))\n",
    "    para = plsq[0]\n",
    "    data_trend = data - func_trend(lat,lon,para)\n",
    "    corr, _ = pearsonr(data, func_trend(lat,lon,para))\n",
    "    return data_trend, para, corr\n",
    "\n",
    "def func_trend(lat,lon,p):\n",
    "    a0,b0,c0,d0 = p\n",
    "    \n",
    "    return a0 + b0*lat + c0*lon +d0*lat*lon\n",
    "\n",
    "def residual_trend(p,lat,lon,y0):\n",
    "    a0,b0,c0,d0 = p \n",
    "    return y0 - func_trend(lat,lon,p)\n",
    "\n",
    "def func_trend_model(lat,lon,p):\n",
    "    lat = lat/180*np.pi\n",
    "    lon = lon/180*np.pi  \n",
    "    lon = lon*np.cos(lat) # to get isometrics coordinates\n",
    "    a0,b0,c0,d0 = p\n",
    "    \n",
    "    return a0 + b0*lat + c0*lon +d0*lat*lon\n",
    "\n",
    "def OK_function(data0):\n",
    "    OK,lat0,lon0,np = data0\n",
    "    z0,s0 = OK.execute('points', lon0, lat0,n_closest_points= np,backend='loop')\n",
    "    return z0,s0\n",
    "\n",
    "def dist_weight_interp(data0):\n",
    "    lat0,lon0,z0,lat1,lon1 = data0\n",
    "    \n",
    "    lat0 = np.asarray(lat0)\n",
    "    lon0 = np.asarray(lon0)\n",
    "    z0 = np.asarray(z0)\n",
    "    \n",
    "    if len(z0)==1:\n",
    "        z0 = z0[0]\n",
    "    nn = len(lat1)\n",
    "    data_interp = np.zeros((nn,))\n",
    "    weight_all = []\n",
    "    for i in range(nn):\n",
    "        dist0 = latlon2dis(lat0,lon0,lat1[i],lon1[i])\n",
    "        weight0 = (1/dist0)**2\n",
    "        if len(weight0) ==1:\n",
    "            weight0 = weight0[0]\n",
    "        weight = weight0/sum(weight0[:])\n",
    "        data_interp[i] = sum(z0*weight)\n",
    "        weight_all.append(weight)\n",
    "    return data_interp,weight_all\n",
    "\n",
    "def latlon2dis(lat1,lon1,lat2,lon2,R=6371):\n",
    "    \n",
    "    lat1 = np.array(lat1)*np.pi/180.0\n",
    "    lat2 = np.array(lat2)*np.pi/180.0\n",
    "    dlon = (lon1-lon2)*np.pi/180.0\n",
    "\n",
    "    # Evaluate trigonometric functions that need to be evaluated more\n",
    "    # than once:\n",
    "    c1 = np.cos(lat1)\n",
    "    s1 = np.sin(lat1)\n",
    "    c2 = np.cos(lat2)\n",
    "    s2 = np.sin(lat2)\n",
    "    cd = np.cos(dlon)\n",
    "\n",
    "    # This uses the arctan version of the great-circle distance function\n",
    "    # from en.wikipedia.org/wiki/Great-circle_distance for increased\n",
    "    # numerical stability.\n",
    "    # Formula can be obtained from [2] combining eqns. (14)-(16)\n",
    "    # for spherical geometry (f=0).\n",
    "\n",
    "    dist =  R*np.arctan2(np.sqrt((c2*np.sin(dlon))**2 + (c1*s2-s1*c2*cd)**2), s1*s2+c1*c2*cd)\n",
    "\n",
    "    return dist\n",
    "    \n",
    "\n",
    "geo_file = '/Users/caoy0a/Documents/SCRATCH/AqabaT87S1A/geometryRadar.h5'\n",
    "date0 = '20160602'\n",
    "    \n",
    "# determine out put file name\n",
    "root_path = '/Users/caoy0a/Documents/SCRATCH/AqabaT87S1A'\n",
    "pyrite_dir = root_path + '/pyrite'\n",
    "era5_dir = pyrite_dir + '/ERA5'\n",
    "era5_raw_dir = era5_dir  + '/raw'\n",
    "era5_sar_dir =  era5_dir  + '/sar'\n",
    "    \n",
    "    \n",
    "# Get raw values from ERA5\n",
    "cdic = ut.initconst()\n",
    "fname0 = glob.glob(era5_raw_dir + '/ERA*' + date0 + '*')[0]\n",
    "lvls,latlist,lonlist,gph,tmp,vpr = ut.get_ecmwf('ERA5',fname0,cdic, humidity='Q')\n",
    "mean_lon = np.mean(lonlist.flatten())\n",
    "if mean_lon > 180:    \n",
    "    lonlist = lonlist - 360.0 # change to insar format lon [-180, 180]\n",
    "    lonlist = np.asarray(lonlist)\n",
    "    \n",
    "lon = lonlist.flatten() \n",
    "lat = latlist.flatten() \n",
    "    \n",
    "lonStep = lonlist[0,1] - lonlist[0,0]\n",
    "latStep = latlist[1,0] - latlist[0,0]\n",
    "    \n",
    "maxlon = max(lonlist[0,:])\n",
    "minlon = min(lonlist[0,:])\n",
    "    \n",
    "maxlat = max(latlist[:,0])\n",
    "minlat = min(latlist[:,0])\n",
    "        \n",
    "Rescale = 10 # default 5  around ~ 6km\n",
    "lonStep1 = lonStep/Rescale\n",
    "latStep1 = latStep/Rescale\n",
    "    \n",
    "lonv = np.arange(minlon,maxlon,lonStep1)\n",
    "latv = np.arange(maxlat,minlat,latStep1)\n",
    "    \n",
    "lonvv,latvv = np.meshgrid(lonv,latv)\n",
    "    \n",
    "    \n",
    "# Make a height scale\n",
    "hgt = np.linspace(cdic['minAltP'], gph.max().round(), cdic['nhgt'])\n",
    "# Interpolate pressure, temperature and Humidity of hgt\n",
    "[Pi,Ti,Vi] = ut.intP2H(lvls, hgt, gph, tmp, vpr, cdic)\n",
    "# Calculate the delays\n",
    "[DDry,DWet] = ut.PTV2del(Pi,Ti,Vi,hgt,cdic)\n",
    "    \n",
    "hgt0 = hgt.copy()\n",
    "idx0 = np.where(((-200<hgt0) & (hgt0 < 3000)))\n",
    "hgt00 = hgt0[idx0]\n",
    "    \n",
    "hgt0 = list(hgt0)\n",
    "\n",
    "dd0 = DDry.copy()\n",
    "dw0 = DWet.copy()\n",
    "dt0 = dd0 + dw0\n",
    "    \n",
    "data0 = dt0\n",
    "    \n",
    "nk = len(hgt00)\n",
    "    \n",
    "mdd = np.zeros((nk,),dtype = np.float32)\n",
    "mdw = np.zeros((nk,),dtype = np.float32)\n",
    "mdt = np.zeros((nk,),dtype = np.float32)\n",
    "    \n",
    "for i in range(nk):\n",
    "    mdd[i] = np.mean(dd0[:,:,hgt0.index(hgt00[i])])\n",
    "    mdw[i] = np.mean(dw0[:,:,hgt0.index(hgt00[i])])\n",
    "    mdt[i] = np.mean(dt0[:,:,hgt0.index(hgt00[i])])\n",
    "    \n",
    "    \n",
    "R = 6371    \n",
    "BIN_NUMB = 50\n",
    "max_length = 300\n",
    "range0 = max_length/2\n",
    "model = 'spherical'\n",
    "eng = matlab.engine.start_matlab()\n",
    "row,col = lonvv.shape\n",
    "Delf_dense = np.zeros((nk,row,col),dtype = np.float32)\n",
    "    \n",
    "hx = hgt00.copy()\n",
    "rescale_h = 10 # default 10  around ~ 15 m/level\n",
    "hx_step = hx[1] - hx[0]\n",
    "hx_step2 = hx_step/rescale_h\n",
    "hgt_dense = np.arange(min(hx),max(hx),hx_step2)\n",
    "    \n",
    "## interp horizontal \n",
    "prog_bar = ptime.progressBar(maxValue=nk)\n",
    "#for i in range(nk):\n",
    "method ='kriging'\n",
    "#for i in range(nk):\n",
    "for i in range(1):\n",
    "    k0 = i\n",
    "    tzd = data0[:,:,hgt0.index(hgt00[k0])]\n",
    "    tzd = tzd.flatten()\n",
    "        \n",
    "    if method =='kriging':\n",
    "        tzd0, para, corr= remove_ramp(lat,lon,tzd)\n",
    "        trend = func_trend_model(latvv,lonvv,para)\n",
    "        #trend = trend.reshape(row,col)\n",
    "        uk = OrdinaryKriging(lon, lat, tzd0, coordinates_type = 'geographic', nlags=BIN_NUMB)\n",
    "        Semivariance_trend = 2*(uk.semivariance)    \n",
    "        x0 = (uk.lags)/180*np.pi*R\n",
    "        y0 = Semivariance_trend\n",
    "    \n",
    "        LL0 = x0[x0< max_length]\n",
    "        SS0 = y0[x0< max_length]\n",
    "        sill0 = max(SS0)\n",
    "        sill0 = sill0.tolist()\n",
    "    \n",
    "        LLm = matlab.double(LL0.tolist())\n",
    "        SSm = matlab.double(SS0.tolist()) \n",
    "        tt = eng.variogramfit(LLm,SSm,range0,sill0,[],'nugget',0.00001,'model','spherical')\n",
    "        variogram_para0 = tt[0]\n",
    "    \n",
    "        para = variogram_para0[0:3]\n",
    "        print(para[1])\n",
    "        para[1] = para[1]/R/np.pi*180\n",
    "        #print(para)\n",
    "        uk.variogram_model_parameters = para\n",
    "        z0,s0 = uk.execute('grid', lonv, latv, n_closest_points = 10, backend='loop')\n",
    "            #ax.plot(x0,y0,'r.')\n",
    "        Delf_dense[i,:,:] = z0 + trend\n",
    "    else:\n",
    "        # using scipy.interpolate.griddata\n",
    "        points = np.zeros((len(lon),2),dtype = np.float32)\n",
    "        points[:,0] = lon\n",
    "        points[:,1] = lat\n",
    "        tzd = tzd.reshape(len(tzd),)\n",
    "            \n",
    "        grid_tzd = griddata(points, tzd, (lonvv, latvv), method='linear')\n",
    "        Delf_dense[i,:,:] = grid_tzd\n",
    "        \n",
    "#    prog_bar.update(i+1, every=1, suffix='{}/{} slices'.format(i+1, nk))\n",
    "#prog_bar.close()\n",
    "    \n",
    "## interp latitude\n",
    "nk2 = len(hgt_dense)\n",
    "Delf_dense2 = np.zeros((nk2,row,col),dtype = np.float32)\n",
    "    \n",
    "initial_function = initial_dict['onn_linear']\n",
    "elevation_function = model_dict['onn_linear']\n",
    "residual_function = residual_dict['onn_linear']\n",
    "    \n",
    "    \n",
    "## elevation model and remove\n",
    "y0 = mdt\n",
    "x0 = hgt00\n",
    "p0 = initial_function(x0,y0)\n",
    "plsq = leastsq(residual_function,p0,args = (x0,y0))\n",
    "plsq = leastsq(residual_function,plsq[0],args = (x0,y0))\n",
    "plsq = leastsq(residual_function,plsq[0],args = (x0,y0))\n",
    "plsq = leastsq(residual_function,plsq[0],args = (x0,y0))\n",
    "turb_dense = Delf_dense.copy()\n",
    "\n",
    "#\n",
    "#turb_dense = Delf_dense.copy()\n",
    "\n",
    "#print(hgt_dense)\n",
    "linearint = intp.RegularGridInterpolator((hgt_dense,latv[::-1], lonv), Delf_dense2[:,::-1,:], method='linear', bounds_error=False, fill_value = 0.0)\n",
    "k0 = 0\n",
    "\n",
    "zz0 = Delf_dense[k0,::-1,:]\n",
    "print(zz0.shape)\n",
    "print(zz0)\n",
    "print(Delf_dense2[1,::-1,:])\n",
    "linearint2 = intp.RegularGridInterpolator((latv[::-1], lonv), zz0, method='linear', bounds_error=False, fill_value = 0.0)\n",
    "\n",
    "linearint2 = interpolate.interp2d(latvv.flatten(), lonvv.flatten(), zz0.flatten(), kind='cubic')\n",
    "\n",
    "lov = lonlist[0,:]\n",
    "lav = latlist[:,0]\n",
    "zz00 =data0[:,:,hgt0.index(hgt00[0])]\n",
    "linearint_org = intp.RegularGridInterpolator((lav[::-1], lov), zz00, method='linear', bounds_error=False, fill_value = 0.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "eng.quit()\n",
    "    \n",
    "    ## interp InSAR\n",
    "    \n",
    "    #geo_file = '/Users/caoy0a/Documents/SCRATCH/LosAngelesT71F479D/geometryRadar.h5'\n",
    "datasetNames = ut.get_dataNames(geo_file)\n",
    "meta = ut.read_attr(geo_file)\n",
    "if 'latitude' in datasetNames: \n",
    "    lats = ut.read_hdf5(geo_file,datasetName='latitude')[0]\n",
    "    lons = ut.read_hdf5(geo_file,datasetName='longitude')[0]\n",
    "else:\n",
    "    lats,lons = ut.get_lat_lon(meta)\n",
    "    \n",
    "heis = ut.read_hdf5(geo_file,datasetName='height')[0]\n",
    "row0, col0 = heis.shape\n",
    "val_turb = np.zeros((heis.shape),dtype = np.float32)   \n",
    "val_turb0 = val_turb.flatten()\n",
    "  \n",
    "    \n",
    "z_turb = np.zeros((heis.shape),dtype = np.float32)   \n",
    "z_turb0 = val_turb.flatten()    \n",
    "    \n",
    "    \n",
    "heis0 = heis.flatten()\n",
    "lats0 = lats.flatten()\n",
    "lons0 = lons.flatten()\n",
    "    \n",
    "hh = heis0[~np.isnan(lats0)]\n",
    "lala = lats0[~np.isnan(lats0)]\n",
    "lolo = lons0[~np.isnan(lats0)]\n",
    "    \n",
    "#val_turb22 = linearint2(np.vstack((lala, lolo)).T)\n",
    "val_turb22 = linearint2(lala, lolo)\n",
    "val_turb2 = val_turb0.copy()\n",
    "val_turb2[~np.isnan(lats0)]= val_turb22\n",
    "val_turb2 = val_turb2.reshape(row0,col0)\n",
    "\n",
    "val_turb33 = linearint_org(np.vstack((lala, lolo)).T)\n",
    "val_turb3 = val_turb0.copy()\n",
    "val_turb3[~np.isnan(lats0)]= val_turb33\n",
    "val_turb3 = val_turb3.reshape(row0,col0)\n",
    "\n",
    "\n",
    "\n",
    "meta['UNIT'] = 'm'\n",
    "meta['FILE_TYPE'] = 'delay'\n",
    "    \n",
    "datasetDict = dict()\n",
    "datasetDict['turb_sar'] = val_turb2\n",
    "\n",
    "OUT = '20160602_tzd_kriging.h5'\n",
    "ut.write_h5(datasetDict, OUT, metadata=meta, ref_file=None, compression=None)\n",
    "\n",
    "    \n",
    "datasetDict = dict()\n",
    "datasetDict['turb_sar'] = val_turb3\n",
    "\n",
    "OUT = '20160602_tzd_griddata.h5'\n",
    "ut.write_h5(datasetDict, OUT, metadata=meta, ref_file=None, compression=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
